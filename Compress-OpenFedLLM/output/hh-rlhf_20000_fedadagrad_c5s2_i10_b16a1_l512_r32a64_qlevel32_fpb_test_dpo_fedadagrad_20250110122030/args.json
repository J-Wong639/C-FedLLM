{
    "script_args": {
        "model_name_or_path": "ehartford/Wizard-Vicuna-7B-Uncensored",
        "dataset_name": "Anthropic/hh-rlhf",
        "log_with": "none",
        "learning_rate": 0.0005,
        "batch_size": 16,
        "seq_length": 512,
        "gradient_accumulation_steps": 1,
        "load_in_8bit": true,
        "load_in_4bit": false,
        "use_peft": true,
        "trust_remote_code": false,
        "output_dir": "./output/hh-rlhf_20000_fedadagrad_c5s2_i10_b16a1_l512_r32a64_qlevel32_fpb_test_dpo_fedadagrad_20250110122030",
        "peft_lora_r": 32,
        "peft_lora_alpha": 64,
        "logging_steps": 100,
        "use_auth_token": false,
        "num_train_epochs": 3,
        "max_steps": 10,
        "save_steps": 1000,
        "save_total_limit": 10,
        "push_to_hub": false,
        "hub_model_id": null,
        "gradient_checkpointing": true,
        "template": "vicuna_v1.1",
        "seed": 2023,
        "dpo_beta": 0.1,
        "dataset_sample": 20000,
        "local_data_dir": null,
        "special_sign": "test_dpo_fedadagrad"
    },
    "fed_args": {
        "fed_alg": "fedadagrad",
        "num_rounds": 200,
        "num_clients": 5,
        "sample_clients": 2,
        "split_strategy": "iid",
        "prox_mu": 0.01,
        "fedopt_tau": 0.001,
        "fedopt_eta": 0.001,
        "fedopt_beta1": 0.9,
        "fedopt_beta2": 0.99,
        "save_model_freq": 201,
        "is_quantized": false,
        "quantize_level": 32,
        "test_dataset": "fpb",
        "test_batch_size": 16,
        "test_model_freq": 200,
        "subspace_change_freq": 10,
        "is_change_subspace": false,
        "subspace_rank": 2
    }
}